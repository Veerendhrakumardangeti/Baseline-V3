(ptbxl-venv) PS C:\Users\dines> python train_pdd.py `
>>   --data_dir C:\Users\dines\results\baseline `
>>   --difficulty C:\Users\dines\results\baseline\difficulty.npy `
>>   --model inception `
>>   --epochs 30 `
>>   --batch_size 32 `
>>   --ckpt_dir C:\Users\dines\results\pdd_final `
>>   --easy_pct 0.2 `
>>   --medium_pct 0.8 `
>>   --gamma 0.98 `
>>   --num_workers 0
[INFO] Detected input channels: 12. Signal length: 1000
Epoch 1: using 2049 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 1/30  Train Loss=0.4585 Acc=0.8873  Val Loss=0.7573 Acc=0.7500
Saved best model

Epoch 2: using 2024 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 2/30  Train Loss=0.1276 Acc=0.9812  Val Loss=0.7289 Acc=0.7500
Epoch 3: using 1960 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 3/30  Train Loss=0.0424 Acc=0.9974  Val Loss=0.8251 Acc=0.7500
Epoch 4: using 1931 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 4/30  Train Loss=0.0180 Acc=1.0000  Val Loss=0.9442 Acc=0.7857
Saved best model

Epoch 5: using 1901 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 5/30  Train Loss=0.0125 Acc=1.0000  Val Loss=0.8231 Acc=0.7500
Epoch 6: using 1860 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 6/30  Train Loss=0.0096 Acc=1.0000  Val Loss=0.9083 Acc=0.7857
Epoch 7: using 1810 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 7/30  Train Loss=0.0061 Acc=1.0000  Val Loss=0.8429 Acc=0.7500
Epoch 8: using 1790 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 8/30  Train Loss=0.0031 Acc=1.0000  Val Loss=0.9491 Acc=0.7500
Epoch 9: using 1720 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 9/30  Train Loss=0.0025 Acc=1.0000  Val Loss=0.9871 Acc=0.7500
Epoch 10: using 1695 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 10/30  Train Loss=0.0025 Acc=1.0000  Val Loss=1.0410 Acc=0.7500
Epoch 11: using 1672 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 11/30  Train Loss=0.0020 Acc=1.0000  Val Loss=1.0932 Acc=0.7857
Epoch 12: using 1627 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 12/30  Train Loss=0.0017 Acc=1.0000  Val Loss=1.0038 Acc=0.7500
Epoch 13: using 1616 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 13/30  Train Loss=0.0018 Acc=1.0000  Val Loss=1.1006 Acc=0.7500
Epoch 14: using 1551 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 14/30  Train Loss=0.0027 Acc=1.0000  Val Loss=1.1338 Acc=0.7500
Epoch 15: using 382 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 15/30  Train Loss=0.0490 Acc=0.9869  Val Loss=2.7608 Acc=0.2500
Epoch 16: using 377 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 16/30  Train Loss=0.1048 Acc=0.9735  Val Loss=2.4099 Acc=0.7143
Epoch 17: using 369 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 17/30  Train Loss=0.0799 Acc=0.9864  Val Loss=1.2411 Acc=0.7500
Epoch 18: using 392 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 18/30  Train Loss=0.0557 Acc=0.9872  Val Loss=0.7809 Acc=0.8214
Saved best model

Epoch 19: using 379 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 19/30  Train Loss=0.0608 Acc=0.9894  Val Loss=0.7033 Acc=0.7857
Epoch 20: using 344 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 20/30  Train Loss=0.0550 Acc=0.9767  Val Loss=1.2174 Acc=0.7500
Epoch 21: using 343 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 21/30  Train Loss=0.0427 Acc=0.9883  Val Loss=0.7902 Acc=0.7500
Epoch 22: using 325 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 22/30  Train Loss=0.0159 Acc=1.0000  Val Loss=0.5864 Acc=0.7857
Epoch 23: using 337 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 23/30  Train Loss=0.0113 Acc=1.0000  Val Loss=0.9547 Acc=0.7500
Epoch 24: using 325 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 24/30  Train Loss=0.0114 Acc=1.0000  Val Loss=0.8014 Acc=0.7500
Epoch 25: using 303 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 25/30  Train Loss=0.0372 Acc=0.9967  Val Loss=1.1319 Acc=0.7143
Epoch 26: using 299 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 26/30  Train Loss=0.0228 Acc=0.9933  Val Loss=0.7966 Acc=0.8214
Epoch 27: using 286 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 27/30  Train Loss=0.0107 Acc=1.0000  Val Loss=1.0513 Acc=0.8214
Epoch 28: using 271 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 28/30  Train Loss=0.0068 Acc=1.0000  Val Loss=1.0090 Acc=0.7857
Epoch 29: using 283 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 29/30  Train Loss=0.0045 Acc=1.0000  Val Loss=0.9261 Acc=0.7857
Epoch 30: using 298 / 213 samples
[DEBUG] batch 0 — x.shape: torch.Size([32, 12, 1000]), x.dtype: torch.float32, device: cpu
Epoch 30/30  Train Loss=0.0048 Acc=1.0000  Val Loss=0.7380 Acc=0.8214